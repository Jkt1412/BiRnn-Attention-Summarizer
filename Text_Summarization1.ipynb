{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvTzv024CFxE"
   },
   "source": [
    "# Get BBC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28811,
     "status": "ok",
     "timestamp": 1553949324231,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "-Ss8zFVjCxhN",
    "outputId": "4ff2f431-6d77-4c40-c4e9-8ccce4eb02cb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"./gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1416,
     "status": "ok",
     "timestamp": 1553949326682,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "X33wMiJNDV5U",
    "outputId": "c4f407ce-53be-4a0c-e0e4-a40210a4c80f"
   },
   "outputs": [],
   "source": [
    "cd gdrive/My\\ Drive/Colab\\ Notebooks/Datasets/Text\\ Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7649,
     "status": "ok",
     "timestamp": 1553948600015,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "XFb-bEcejbtG",
    "outputId": "fd38894f-45af-4421-d48b-9b4b307edc44"
   },
   "outputs": [],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXmwymrPDflS"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('myfile.pkl','rb') as fp:\n",
    "  heading, article = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1553208395273,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "NzWaAh-ihQA8",
    "outputId": "cbcbd2f4-626f-42f6-ec50-b3314fd63f6b"
   },
   "outputs": [],
   "source": [
    "article[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1057,
     "status": "ok",
     "timestamp": 1553208390522,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "-ouKCPCWbw1b",
    "outputId": "4ee33be6-3eb9-4514-ca1d-08514cf8f9b8"
   },
   "outputs": [],
   "source": [
    "heading[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyhdhBkEVgi"
   },
   "source": [
    "**Data from BBC News Dataset Loaded. The variables are *heading* and *article***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6eaGtlz-E3Yx"
   },
   "source": [
    "# Preprocess the Data , remove the \\n\\n and \\xa0 , lower case everything  (stemming/lemmatization advantageous? Try it out later)\n",
    "\n",
    "## I think I should keep the comma's in for now , maybe the Attention mechanism later would find words near a comma a good place to give attention to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVg5fSryGfAF"
   },
   "outputs": [],
   "source": [
    "heading = [h.lower() for h in heading]\n",
    "article = [a.lower() for a in article]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wC_iQj2GmP0"
   },
   "outputs": [],
   "source": [
    "article = [a.replace('\\n','').replace('\\xa0',' ') for a in article]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1553208448156,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "Uj4Eii5gb-yy",
    "outputId": "9dadce87-317e-4f0f-9885-ba29afa82e93"
   },
   "outputs": [],
   "source": [
    "article[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZsunLje_TdH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1283,
     "status": "ok",
     "timestamp": 1553208458769,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "MW_j9LF7cCiT",
    "outputId": "d0d1c783-f64c-4c0a-d78a-f9367bcde256"
   },
   "outputs": [],
   "source": [
    "heading[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDC4tH40I-2C"
   },
   "source": [
    "# Toeknize the data , Make Word Embeddings from GloVe\n",
    "\n",
    "## Mainly what I have to do is make a matrix of size (vocab_size, 100) which I can initialize as my weight matrix. Be careful, for now I am assuming no new words can appear in a text other than the ones I have seen before , so later if this works improve it to take in other words too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4THBv0WJF6k"
   },
   "outputs": [],
   "source": [
    "word_dimensions = 100\n",
    "import pandas as pd\n",
    "df = pd.read_csv('glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nE9viBdPNO1r"
   },
   "outputs": [],
   "source": [
    "glove = {key: val.values for key, val in df.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1YyKHeQFjJ0"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3kYN7skNU2G"
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "for a in article:\n",
    "  tokenized_text = tokenizer.tokenize(a)\n",
    "  for tokens in tokenized_text:\n",
    "    words.append(tokens)\n",
    "    \n",
    "for h in heading:\n",
    "  tokenized_text = tokenizer.tokenize(h)\n",
    "  for tokens in tokenized_text:\n",
    "    words.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17034
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1553758535038,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "5SxM19TaOaDd",
    "outputId": "f5275f54-4998-43c7-fecc-9b5105dd972b"
   },
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QK1w4y1OAW0"
   },
   "outputs": [],
   "source": [
    "wordcounts = Counter(words).most_common(170000)\n",
    "vocab_list = np.array([word for word,_ in wordcounts])\n",
    "dictionary_word_code = {word:code for code,word in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2822
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22305,
     "status": "ok",
     "timestamp": 1553208517886,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "uDvTMhHeBgNy",
    "outputId": "a1107068-4a66-4221-fa87-07fd00eb2792"
   },
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "i = 0\n",
    "while i != vocab_list.shape[0] :\n",
    "  try:\n",
    "    embedding_list.append(glove[vocab_list[i]])\n",
    "    i = i+1\n",
    "  except KeyError as e:\n",
    "    embedding_list.append(np.random.normal(0,0.1,[word_dimensions]))\n",
    "    i = i+1\n",
    "    \n",
    "  if i%1000 == 0:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psAAqFnZX6w_"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1553208540707,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "K_L70jolcWA7",
    "outputId": "84d398ba-b25d-4ac2-955a-68131b5f8147"
   },
   "outputs": [],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XY8MVbKYsGg"
   },
   "source": [
    "**Embedding Matrix is created and in the variable *embedding_matrix***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSQyd9qvY_wT"
   },
   "source": [
    "# Making a Bi-Directional RNN with Attention , no dropout layer\n",
    "\n",
    "## For now making a 3 Layer LSTM deep network (could cause vanishing gradient problem) and not using the EOS thing, will make the summary a fixed number of words , mostly wont be coherent but lets see if any output comes at all first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hh-3a2AHX8U7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PE4eDmUgA6Vz"
   },
   "source": [
    "#### 'The' also has a code of 0 and you are gonna zero pad things so could lead to problems\n",
    "\n",
    "#### Also you are using too much RAM afterwards change variable names so you overwriting them and not keep making new ones\n",
    "Ok so for saving RAM I am thinking I will make a pickle file for all the important stuff and load it in so all the useless variables dont take up space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkCdPTRG1b5I"
   },
   "outputs": [],
   "source": [
    "tokenized_articles = []\n",
    "tokenized_headings = []\n",
    "for a in article:\n",
    "  tokens = tokenizer.tokenize(a)\n",
    "  tokenized_articles.append(tokens)\n",
    "for h in heading:\n",
    "  tokens = tokenizer.tokenize(h)\n",
    "  tokenized_headings.append(tokens)\n",
    "  \n",
    "max_length_article = max([len(a) for a in tokenized_articles])\n",
    "max_length_heading = max([len(h) for h in tokenized_headings])\n",
    "\n",
    "numerical_articles = []\n",
    "numerical_headings = []\n",
    "for a in tokenized_articles:\n",
    "    list1 = [dictionary_word_code[b] for b in a]\n",
    "    numerical_articles.append(list1)\n",
    "for h in tokenized_headings:\n",
    "  list1 = [dictionary_word_code[b] for b in h]\n",
    "  numerical_headings.append(list1)\n",
    "  \n",
    "padded_numerical_articles = []\n",
    "padded_numerical_headings = []\n",
    "for a in numerical_articles:\n",
    "  zeros = [0]*(max_length_article - len(a))\n",
    "  list1 = a + zeros\n",
    "  padded_numerical_articles.append(list1)\n",
    "for h in numerical_headings:\n",
    "  zeros = [0]*(max_length_heading - len(h))\n",
    "  list1 = h + zeros\n",
    "  padded_numerical_headings.append(list1)\n",
    "  \n",
    "with open(\"input_data.pickle\", \"wb\") as f:\n",
    "    pickle.dump((embedding_matrix,padded_numerical_articles,padded_numerical_headings,vocab_list), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0eeO97yHjAp"
   },
   "source": [
    "# Too much RAM was used so start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nfbmW_XAPL8"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(\"input_data.pickle\",\"rb\") as f:\n",
    "  embedding_matrix , articles , headings, vocab_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[617, 57, 40, 608, 957, 624, 16, 65875, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headings[4][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.1055e-01,  9.0581e-02,  8.3619e-01,  3.5460e-02,  6.2207e-01,\n",
       "        1.3999e-01,  2.2168e-01,  4.7963e-01, -1.7305e-01,  9.0134e-01,\n",
       "       -9.1659e-01, -2.8716e-01,  7.3893e-01,  6.7058e-01,  7.5663e-02,\n",
       "       -6.7974e-01,  7.0522e-01, -1.3754e+00, -7.1724e-01,  5.0368e-01,\n",
       "        1.3067e+00,  5.0400e-01,  2.8449e-01,  1.3976e-01, -2.3781e-01,\n",
       "       -3.8840e-02,  7.0760e-02, -2.1592e-01,  4.4046e-04, -1.3867e-01,\n",
       "       -3.3910e-01, -2.5784e-01,  7.5747e-01, -2.5122e-01,  1.0452e-02,\n",
       "       -4.3676e-01,  2.7547e-01,  1.2042e-01, -6.2303e-03,  4.7675e-02,\n",
       "       -1.1395e+00, -5.0275e-01,  1.5897e-03, -2.3247e-01,  7.0892e-01,\n",
       "        4.8086e-01,  7.8479e-01,  3.2697e-02,  4.3316e-01, -4.2208e-02,\n",
       "       -8.3710e-01,  6.9847e-01,  3.6992e-02,  4.5609e-01, -9.6309e-02,\n",
       "       -1.9597e+00, -3.2724e-01, -9.0069e-01,  2.1099e+00,  3.4440e-01,\n",
       "        3.5036e-01,  7.4752e-01,  3.4476e-01, -5.1286e-01,  5.9623e-01,\n",
       "        2.4991e-01, -4.9013e-01,  3.3827e-01, -3.1357e-02,  3.6480e-01,\n",
       "       -2.4603e-01, -3.3542e-01, -2.1727e-01, -3.5801e-01,  2.9710e-02,\n",
       "       -3.8308e-02,  2.7764e-01,  3.3785e-01, -3.2452e-01,  5.6788e-01,\n",
       "        3.3789e-01, -1.0077e-01, -9.2920e-01,  2.4538e-01, -3.0940e-01,\n",
       "        2.9894e-01, -4.6845e-01, -7.1435e-02,  4.0103e-01,  2.1570e-01,\n",
       "        9.7471e-01, -1.8652e-01, -6.8652e-01,  6.5311e-01, -1.2355e+00,\n",
       "        1.1120e+00, -8.9728e-01,  1.6292e-01,  9.4826e-01,  2.5372e-01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1578]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13xfVE8i54mR"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def next_batch(articles,headings,batch_size,num_time_steps,num_output_steps):                 #850     #84\n",
    "  \n",
    "#   snipped_articles = []\n",
    "#   snipped_headings = []\n",
    "  \n",
    "#   for a in articles:\n",
    "#     part_article = a[0:num_time_steps]\n",
    "#     snipped_articles.append(part_article)\n",
    "    \n",
    "#   random = np.random.randint(0,len(articles) - batch_size -1)\n",
    "#   batch_x = np.array(snipped_articles[random:random+batch_size]).reshape([batch_size,num_time_steps,1])\n",
    "#   onehotlistarticles = []\n",
    "# #  for article in batch_x:\n",
    "# #    for num in article:\n",
    "# #      zeros = np.array([0]*len(vocab_list))\n",
    "# #      zeros[num] = 1\n",
    "# #      onehotlistarticles.append(zeros)\n",
    "# #  onehotlistarticles = np.array(onehotlistarticles).reshape([batch_size,num_time_steps,-1])\n",
    "  \n",
    "#   for h in headings:\n",
    "#     part_heading = h[0:num_output_steps]\n",
    "#     snipped_headings.append(part_heading)\n",
    "  \n",
    "#   batch_y = np.array(snipped_headings[random:random+batch_size]).reshape([batch_size,num_output_steps,1])\n",
    "#   onehotlistheadings = []\n",
    "#   for heading in batch_y:\n",
    "#     for num in heading:\n",
    "#       zeros = np.array([0]*len(vocab_list))\n",
    "#       zeros[num] = 1\n",
    "#       onehotlistheadings.append(zeros)\n",
    "#   onehotlistheadings = np.array(onehotlistheadings).reshape([batch_size,num_output_steps,-1])\n",
    "  \n",
    "#   return onehotlistarticles , onehotlistheadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def next_batch(articles,headings,batch_size,num_time_steps,num_output_steps):                 #850     #84\n",
    "  \n",
    "  snipped_articles = []\n",
    "  snipped_headings = []\n",
    "  \n",
    "  for a in articles:\n",
    "    part_article = a[0:num_time_steps]\n",
    "    snipped_articles.append(part_article)\n",
    "    \n",
    "  #random = np.random.randint(0,len(articles) - batch_size -1)\n",
    "  #batch_x = np.array(snipped_articles[random:random+batch_size]).reshape([batch_size,num_time_steps,1])\n",
    "  batch_x = np.array([snipped_articles[2],snipped_articles[4]]).reshape([batch_size,num_time_steps,1])\n",
    "  embeddedarticles = []\n",
    "  for article in batch_x:\n",
    "    for num in article:\n",
    "        value = embedding_matrix[num]\n",
    "        embeddedarticles.append(value)\n",
    "  \n",
    "  embeddedarticles = np.array(embeddedarticles).reshape([batch_size,num_time_steps,-1])\n",
    "  \n",
    "  for h in headings:\n",
    "    part_heading = h[0:num_output_steps]\n",
    "    snipped_headings.append(part_heading)\n",
    "  \n",
    "  #batch_y = np.array(snipped_headings[random:random+batch_size]).reshape([batch_size,num_output_steps,1])\n",
    "  batch_y = np.array([snipped_headings[2],snipped_headings[4]]).reshape([batch_size,num_output_steps,1])\n",
    "  onehotlistheadings = []\n",
    "  for heading in batch_y:\n",
    "    for num in heading:\n",
    "      zeros = np.array([0]*len(vocab_list))\n",
    "      zeros[num] = 1\n",
    "      onehotlistheadings.append(zeros)\n",
    "  onehotlistheadings = np.array(onehotlistheadings).reshape([batch_size,num_output_steps,-1])\n",
    "  \n",
    "  return embeddedarticles , onehotlistheadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsM5HHVZp1AK"
   },
   "outputs": [],
   "source": [
    "onehotencodedarticle , onehotencodedheading = next_batch(articles,headings,2,350,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1552,
     "status": "ok",
     "timestamp": 1553279355165,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "brEdaUprqVIY",
    "outputId": "7b415c55-00c7-44fd-d1f5-e5951021c685"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 350, 100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1190,
     "status": "ok",
     "timestamp": 1553279324869,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "84xf5k1nqUpK",
    "outputId": "293f074a-03bd-486e-d711-3bfba51a2426"
   },
   "outputs": [],
   "source": [
    "type(embedding_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qhn7_KS4xxsK"
   },
   "source": [
    "# TensorFlow Graph \n",
    "\n",
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMtm5eFZmJ4_"
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "  used = tf.reduce_max(sequence, 2)\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHspC9d0uAdB"
   },
   "source": [
    "**See Imext Notebook for explaination of tf.reduce_max and how axis collapses and stuff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7w2duU_-psS5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvHe14VYgfi-"
   },
   "outputs": [],
   "source": [
    "num_time_steps = 350            #850\n",
    "num_output_steps = 20            #84\n",
    "dimensions_rnn_cell = 50         #100\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSy6Z9ul_hCk"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUlstKfuiH_l"
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape = [None,num_time_steps,embedding_matrix.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lg6xJZRGATVd"
   },
   "source": [
    "** Right now too tired, not initializing with Embedding Matrix as its a pain , have no clue what the fuck the function wants from me, come back later here if the performance is not so good , see the documentation for initializer in LSTMCell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7262,
     "status": "ok",
     "timestamp": 1553949466353,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "NpXY4lXuX8JI",
    "outputId": "8274c3e7-b6db-4399-ef53-fe3a38c2c557"
   },
   "outputs": [],
   "source": [
    "lstm_fw_cell = [tf.nn.rnn_cell.LSTMCell(dimensions_rnn_cell),tf.nn.rnn_cell.LSTMCell(dimensions_rnn_cell)] #,tf.nn.rnn_cell.LSTMCell(dimensions_rnn_cell)]\n",
    "lstm_bw_cell = [tf.nn.rnn_cell.LSTMCell(dimensions_rnn_cell),tf.nn.rnn_cell.LSTMCell(dimensions_rnn_cell)] #,tf.nn.rnn_cell.LSTMCell(dimensions_rnn_cell)]\n",
    "\n",
    "outputs, output_state_fw, output_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, X, dtype='float32', sequence_length = length(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXwjpyP4DcLb"
   },
   "source": [
    "** Cool so session crashes after using all the RAM**\n",
    "\n",
    "** For testing if this is working or not **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBs4xL9Sy6Vs"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  batch_x, v = next_batch(articles,headings,batch_size,100,10)\n",
    "  combined_bi_rnn_output = sess.run(outputs,feed_dict = {X:batch_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1553759327090,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "njEL3Nz0y8TD",
    "outputId": "c2021343-0ed2-441f-a5ec-a811bfab1bdb"
   },
   "outputs": [],
   "source": [
    "combined_bi_rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEsTD4P27-QQ"
   },
   "outputs": [],
   "source": [
    "## Attention Mechanism : For now, wont be taking input from the final output of the network and lets see how it performs, afterwards take as input from the output of the final stage too \n",
    "\n",
    "## I think thats possible because the final outputs are also placeholders right? So that can be input to your 'neural_network' function\n",
    "\n",
    "### Define a Neural Network basically 200 : 100 : 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTQlXl13vWAU"
   },
   "outputs": [],
   "source": [
    "combined_BiRNN_outputs = tf.placeholder(tf.float32,shape = [None,num_time_steps,2*dimensions_rnn_cell])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANT71WCevWAX"
   },
   "outputs": [],
   "source": [
    "num_hidden_neurons = 30\n",
    "def neural_network(combined_BiRnn_output):\n",
    "    \n",
    "    Wx1 = tf.Variable(tf.random_normal([batch_size,2*dimensions_rnn_cell,num_hidden_neurons],1,1/100))\n",
    "    Wx2 = tf.Variable(tf.random_normal([batch_size,num_hidden_neurons,num_output_steps],1,1/30))\n",
    "    b1 = tf.Variable(tf.constant(0.0,shape = [num_hidden_neurons]))\n",
    "    b2 = tf.Variable(tf.constant(0.0,shape = [num_output_steps]))\n",
    "    first_out = tf.nn.tanh(tf.add(tf.matmul(combined_BiRnn_output,Wx1),b1))\n",
    "    e = tf.nn.relu(tf.add(tf.matmul(first_out,Wx2),b2))\n",
    "        \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VQDdOravWAZ"
   },
   "outputs": [],
   "source": [
    "def softmax(e_values):\n",
    "    j = tf.exp(e_values)\n",
    "    totals = tf.reduce_sum(j,1)\n",
    "    j = tf.unstack(j,axis = 0)\n",
    "    totals = tf.unstack(totals, axis = 0)\n",
    "    for i in range(batch_size):\n",
    "        j[i] = j[i]/totals[i]\n",
    "    j = tf.stack(j,axis = 0)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlE0DQWqvWAc"
   },
   "outputs": [],
   "source": [
    "e_vals = neural_network(combined_BiRNN_outputs)\n",
    "alpha_values = softmax(e_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkN_bf17vWAi"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVD3ollgvWAk"
   },
   "source": [
    "** To test whether alpha values are coming or not **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qeu9WinxvWAm"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_x, _ = next_batch(articles,headings,batch_size,num_time_steps,num_output_steps)\n",
    "    outs = sess.run(outputs,feed_dict = {X: batch_x})\n",
    "    \n",
    "    alpha = sess.run(alpha_values,feed_dict = {combined_BiRNN_outputs:outs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1124,
     "status": "ok",
     "timestamp": 1553759448339,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "QUmgO-0WR59c",
    "outputId": "9c1022d3-8596-4075-852f-273dde46e6cd"
   },
   "outputs": [],
   "source": [
    "alpha[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0d2ZC8X_vWAp"
   },
   "source": [
    "** Weighted Average **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3H73NLW_vWAr"
   },
   "outputs": [],
   "source": [
    "def weighted_average(outputs,alphas):\n",
    "    \n",
    "    alphas = tf.transpose(alphas,perm = [0,2,1])\n",
    "    context_vectors = tf.matmul(alphas,outputs)\n",
    "    \n",
    "    return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UuuK1tQtvWAv"
   },
   "outputs": [],
   "source": [
    "context_vectors = weighted_average(combined_BiRNN_outputs,alpha_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJ7b1tolvWA1"
   },
   "source": [
    "### Another idea you could do is instead of one hot encoding the input words use the embedding matrix you created, though wont be as useful if you could load up the embedding matrix as the weight vector it may be better than normal one hot encoding\n",
    "\n",
    "### Or use a LSTM cell as the first layer and top it off with 2 BiRnn layers or something if LSTM cell supports initialzing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vhu5DFy1vWA3"
   },
   "outputs": [],
   "source": [
    "context = tf.placeholder(tf.float32,shape = [batch_size,num_output_steps,2*dimensions_rnn_cell])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGKxTECavWBD"
   },
   "outputs": [],
   "source": [
    "cell_factory = tf.nn.rnn_cell.LSTMCell(dimensions_rnn_cell,activation=tf.nn.relu)\n",
    "initial_state = cell_factory.zero_state(batch_size, dtype=tf.float32)\n",
    "decoder, _ = tf.nn.dynamic_rnn(cell_factory,context,initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKDYU-NLvWBJ"
   },
   "outputs": [],
   "source": [
    "def output_neural_network(decoder_rnn):\n",
    "    \n",
    "    Wx1 = tf.Variable(tf.random_normal([batch_size,dimensions_rnn_cell,len(vocab_list)],0.5,1/dimensions_rnn_cell))\n",
    "    b1 = tf.Variable(tf.constant(0.0,shape = [len(vocab_list)]))\n",
    "    first_out = tf.nn.relu((tf.add(tf.matmul(decoder_rnn,Wx1),b1)))\n",
    "        \n",
    "    return first_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSpDOiUbvWBO"
   },
   "outputs": [],
   "source": [
    "probability_distribution = output_neural_network(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_az7h5NSxPet"
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape = [None,num_output_steps,len(vocab_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqQ8dtuOvWBT"
   },
   "outputs": [],
   "source": [
    "c_e = tf.nn.softmax_cross_entropy_with_logits_v2(logits = probability_distribution,labels = y_true)\n",
    "c_e_s = tf.reduce_mean(c_e)\n",
    "mse = tf.reduce_mean(tf.square(probability_distribution-y_true))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.002)\n",
    "train = optimizer.minimize(c_e_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdhC7Ih5nDo6"
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x , batch_y = next_batch(articles,headings,batch_size,num_time_steps,num_output_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "v7KyPVBWvWBX",
    "outputId": "16c3166f-543e-4f06-dbf8-408c99e5ef54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy at Step 0 : \n",
      "12.011901\n",
      "\n",
      "\n",
      "Cross entropy at Step 100 : \n",
      "3.7819781\n",
      "\n",
      "\n",
      "Cross entropy at Step 200 : \n",
      "1.4775839\n",
      "\n",
      "\n",
      "Cross entropy at Step 300 : \n",
      "0.4913013\n",
      "\n",
      "\n",
      "Cross entropy at Step 400 : \n",
      "0.46957612\n",
      "\n",
      "\n",
      "Cross entropy at Step 500 : \n",
      "0.16683465\n",
      "\n",
      "\n",
      "Cross entropy at Step 600 : \n",
      "0.16398625\n",
      "\n",
      "\n",
      "Cross entropy at Step 700 : \n",
      "0.019562729\n",
      "\n",
      "\n",
      "Cross entropy at Step 800 : \n",
      "0.0073215715\n",
      "\n",
      "\n",
      "Cross entropy at Step 900 : \n",
      "0.011216141\n",
      "\n",
      "\n",
      "Cross entropy at Step 1000 : \n",
      "0.008925385\n",
      "\n",
      "\n",
      "Cross entropy at Step 1100 : \n",
      "0.0013101394\n",
      "\n",
      "\n",
      "Cross entropy at Step 1200 : \n",
      "0.0927291\n",
      "\n",
      "\n",
      "Cross entropy at Step 1300 : \n",
      "0.00050191407\n",
      "\n",
      "\n",
      "Cross entropy at Step 1400 : \n",
      "0.0006299371\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  #batch_x , batch_y = next_batch(articles,headings,batch_size,num_time_steps,num_output_steps)\n",
    "  for i in range(1500):\n",
    "    outs = sess.run(outputs, feed_dict = {X:batch_x})\n",
    "    con = sess.run(context_vectors, feed_dict = {combined_BiRNN_outputs:outs})\n",
    "    sess.run(train, feed_dict = {context:con,y_true:batch_y})\n",
    "    \n",
    "    if i%100 == 0:\n",
    "      print('Cross entropy at Step {0} : '.format(i))\n",
    "      print(sess.run(c_e_s,feed_dict = {context:con,y_true:batch_y}))\n",
    "      print(\"\\n\")\n",
    "      \n",
    "  saver.save(sess,'./imext_summarizer_1.ckpt')\n",
    "      \n",
    "    #batch_x , batch_y = next_batch(articles,headings,1,100,10)\n",
    "    #outs = sess.run(outputs, feed_dict = {X:batch_x})\n",
    "    #con = sess.run(context_vectors, feed_dict = {combined_BiRNN_outputs:outs})\n",
    "    #final_output = sess.run(probability_distribution, feed_dict = {context:con})\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1378,
     "status": "ok",
     "timestamp": 1553793564468,
     "user": {
      "displayName": "Jeet Thaker",
      "photoUrl": "https://lh4.googleusercontent.com/-jNjv1rf_vkQ/AAAAAAAAAAI/AAAAAAAAACk/hecSejvkvPM/s64/photo.jpg",
      "userId": "18423117888903233743"
     },
     "user_tz": -330
    },
    "id": "wDaBB_NLyrLl",
    "outputId": "695708ed-28c7-49a1-f7e0-edeef9abe8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./imext_summarizer.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./imext_summarizer.ckpt')\n",
    "    \n",
    "    outs = sess.run(outputs, feed_dict = {X:batch_x})\n",
    "    con = sess.run(context_vectors, feed_dict = {combined_BiRNN_outputs:outs})\n",
    "    final_output = sess.run(probability_distribution, feed_dict = {context:con})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1kIjphCT9vC"
   },
   "outputs": [],
   "source": [
    "numerical_words = np.argmax(final_output[1],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  617,   617,    40,   957,   957,   624,    16, 65875,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pay',\n",
       " 'pay',\n",
       " 'or',\n",
       " 'legal',\n",
       " 'legal',\n",
       " 'action',\n",
       " ':',\n",
       " 'dbkl',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = []\n",
    "for i in numerical_words:\n",
    "    head.append(vocab_list[i])\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kuala',\n",
       " 'lumpur',\n",
       " ',',\n",
       " 'sept',\n",
       " '15',\n",
       " '(',\n",
       " 'mysinchew',\n",
       " ')',\n",
       " '--',\n",
       " 'the',\n",
       " 'kuala',\n",
       " 'lumpur',\n",
       " 'city',\n",
       " 'hall',\n",
       " 'today',\n",
       " 'issued',\n",
       " 'an',\n",
       " 'ultimatum',\n",
       " 'to',\n",
       " 'bersih',\n",
       " '2',\n",
       " '.',\n",
       " '0',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'the',\n",
       " 'clean',\n",
       " '-',\n",
       " 'up',\n",
       " 'bill',\n",
       " 'by',\n",
       " 'this',\n",
       " 'month',\n",
       " 'or',\n",
       " 'face',\n",
       " 'legal',\n",
       " 'action',\n",
       " '.',\n",
       " 'deputy',\n",
       " 'federal',\n",
       " 'territories',\n",
       " 'minister',\n",
       " 'datuk',\n",
       " 'loga',\n",
       " 'bala',\n",
       " 'mohan',\n",
       " 'jaganathan',\n",
       " 'said',\n",
       " 'the',\n",
       " 'bill',\n",
       " 'amounting',\n",
       " 'to',\n",
       " 'rm61',\n",
       " ',',\n",
       " '840',\n",
       " 'includes',\n",
       " 'the',\n",
       " 'monitoring',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'cleaning',\n",
       " 'of',\n",
       " 'banners',\n",
       " 'and',\n",
       " 'graffiti',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'repair',\n",
       " 'of',\n",
       " 'damaged',\n",
       " 'infrastructure',\n",
       " '.',\n",
       " 'he',\n",
       " 'said',\n",
       " 'dbkl',\n",
       " 'would',\n",
       " 'bring',\n",
       " 'this',\n",
       " 'matter',\n",
       " 'to',\n",
       " 'the',\n",
       " 'court',\n",
       " 'if',\n",
       " 'bersih',\n",
       " '2',\n",
       " '.',\n",
       " '0',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'up',\n",
       " '.',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " ...]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arti = []\n",
    "for i in articles[4]:\n",
    "    arti.append(vocab_list[i])\n",
    "arti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0624722 , 0.7482909 , 0.74595886, 0.7296468 , 0.75318635,\n",
       "       1.0530317 , 0.7479545 , 0.73764735, 0.7419779 , 0.7319958 ,\n",
       "       1.0751667 , 0.7368156 , 0.73758227, 0.7393745 , 0.7449087 ,\n",
       "       0.7447227 , 0.8921968 , 0.74505943, 0.9990449 , 0.7408533 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output[0][0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text_Summarization.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
